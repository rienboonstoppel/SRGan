{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import random\n",
    "import torch\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_tio import Normalize, ImagePair, calculate_overlap\n",
    "import torchvision\n",
    "from models.generator import GeneratorRRDB\n",
    "from trainer_org import LitTrainer as LitTrainer_org\n",
    "from trainer_gan import LitTrainer as LitTrainer_gan\n",
    "import pytorch_lightning as pl\n",
    "from models.discriminator import Discriminator\n",
    "from models.feature_extractor import FeatureExtractor\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "import time\n",
    "from utils import save_subject\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'learning_rate': 0.0001,\n",
    "#     'patch_size': 224,\n",
    "#     'batch_size': 16,\n",
    "#     'patients_frac': 0.5,\n",
    "#     'patch_overlap': 0.5,\n",
    "#     'optimizer': 'adam',\n",
    "#     'edge_loss': 2,\n",
    "# }\n",
    "# ckpt_filename = 'checkpoint_{}_{}_{}_{}_{}_{}'.format(config['patch_size'],\n",
    "#                                                       config['batch_size'],\n",
    "#                                                       config['patients_frac'],\n",
    "#                                                       config['edge_loss'],\n",
    "#                                                       config['optimizer'],\n",
    "#                                                       config['learning_rate'],\n",
    "#                                                       )\n",
    "\n",
    "config = model.hparams.config\n",
    "# img_name = 'gen_{}_{}_{}_{}_{}_{}_{}'.format(config['patch_size'],\n",
    "#                                           config['batch_size'],\n",
    "#                                           config['patients_frac'],\n",
    "#                                           config['edge_loss'],\n",
    "#                                           config['optimizer'],\n",
    "#                                           # config['learning_rate'],\n",
    "#                                           config['content'],\n",
    "#                                           config['adversarial'],\n",
    "#                                           )\n",
    "\n",
    "# img_name = 'real_gen_{}'.format(config['patch_size'])\n",
    "# subject['gen_hr'].save(os.path.join('output', img_name+'_2.dcm'))\n",
    "# subject['gen_hr'].save(os.path.join('output'))#, img_name+'_2.dcm'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pl.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "dict = {'alpha_content': 0.01,\n",
    "        'patients_frac': 0.1,\n",
    "        }\n",
    "\n",
    "fname = json.dumps(dict)\n",
    "\n",
    "# fname = \"{'alpha_content': 0.01}\"\n",
    "# fname = \"{'alpha_content': 0.01, 'patients_frac': 0.1}\"\n",
    "\n",
    "chars = ['\"', '{', '}', '. ', '_']\n",
    "\n",
    "for char in chars:\n",
    "\tfname = fname.replace(char, '')\n",
    "fname = fname.replace(': ', '_')\n",
    "fname = fname.replace(', ', '-')\n",
    "fname = fname.replace('.', ',')\n",
    "\n",
    "\n",
    "\n",
    "print(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "dict = {'alpha_content': 0.01,\n",
    "        'patients_frac': 0.1,\n",
    "        }\n",
    "\n",
    "print(json.dumps(dict))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import cv2\n",
    "\n",
    "def save_images_from_event(path):\n",
    "    event_acc = event_accumulator.EventAccumulator(path, size_guidance={'images': 0})\n",
    "    event_acc.Reload()\n",
    "    path, fname = os.path.split(path)\n",
    "    for tag in event_acc.Tags()['images']:\n",
    "        events = event_acc.Images(tag)\n",
    "        tag_name = tag.replace('/', ' ')\n",
    "        tag_path = os.path.join(path, 'images', tag_name)\n",
    "        os.makedirs(tag_path, exist_ok=True)\n",
    "        for index, event in enumerate(events):\n",
    "            s = np.frombuffer(event.encoded_image_string, dtype=np.uint8)\n",
    "            image = cv2.imdecode(s, cv2.IMREAD_GRAYSCALE)\n",
    "            fname = '{:04}.jpg'.format(index)\n",
    "            cv2.imwrite(os.path.join(tag_path, fname), image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = '/mnt/beta/djboonstoppel/Code/log/wgan/version_6/events.out.tfevents.1644858303.shire.2157378.0'\n",
    "save_images_from_event(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'learning_rate': 1e-4,\n",
    "    # 'patch_size': args.patch_size,\n",
    "    # 'batch_size': args.batch_size,\n",
    "    'patients_frac': 0.5,\n",
    "    'patch_overlap': 0.5,\n",
    "    'optimizer': 'adam',\n",
    "    'edge_loss': 2,\n",
    "    'b1': 0.9,\n",
    "    'b2': 0.5,\n",
    "    'alpha_content': 1,\n",
    "}\n",
    "\n",
    "# print (\"{:<8} {:<15} {:<10}\".format('Name','Age','Percent'))\n",
    "\n",
    "for key in config:\n",
    "    # name, age, perc = v\n",
    "    print (\"{:<13}: {:<10} \".format(key, config[key]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for patches_batch in patch_loader:\n",
    "        i += 1\n",
    "        imgs_lr, imgs_hr = patches_batch['LR'][tio.DATA].squeeze(4), patches_batch['HR'][tio.DATA].squeeze(4)\n",
    "        if i == 5:\n",
    "            imgs_lr = imgs_lr[200,0,:,:]*std\n",
    "            save_image(imgs_lr, 'imgs_lr.png')\n",
    "            print(imgs_lr.shape)\n",
    "            np.savetxt('imgs_lr.csv', imgs_lr.numpy(), delimiter=',')\n",
    "    print(i)\n",
    "        # gen_hr = model(imgs_lr.to(device)).unsqueeze(4)\n",
    "        # locations = patches_batch[tio.LOCATION]\n",
    "        # aggregator.add_batch(gen_hr, locations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'ragan': False,\n",
    "    'learning_rate': 1e-4,\n",
    "    'patch_size': 64,\n",
    "    'batch_size': 256,\n",
    "    'patients_frac': 0.5,\n",
    "    'patch_overlap': 0.5,\n",
    "    'optimizer': 'adam',\n",
    "    'edge_loss': 2,\n",
    "    'b1': 0.9,\n",
    "    'b2': 0.5,\n",
    "    'alpha_content': 1,\n",
    "}\n",
    "if config['ragan']:\n",
    "    print('RaGAN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "\n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discriminator = Discriminator(input_shape=(3, 256, 256))\n",
    "\n",
    "summary(discriminator, input_size=(3, 256, 256), batch_size=32, device='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DenseResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(DenseResidualBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "        def block(in_features, non_linearity=True):\n",
    "            layers = [nn.Conv2d(in_features, filters, 3, 1, 1, bias=True)]\n",
    "            if non_linearity:\n",
    "                layers += [nn.LeakyReLU()]\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.b1 = block(in_features=1 * filters)\n",
    "        self.b2 = block(in_features=2 * filters)\n",
    "        self.b3 = block(in_features=3 * filters)\n",
    "        self.b4 = block(in_features=4 * filters)\n",
    "        self.b5 = block(in_features=5 * filters, non_linearity=False)\n",
    "        self.blocks = [self.b1, self.b2, self.b3, self.b4, self.b5]\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(inputs)\n",
    "            inputs = torch.cat([inputs, out], 1)\n",
    "        return out.mul(self.res_scale) + x\n",
    "\n",
    "\n",
    "class ResidualInResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(ResidualInResidualDenseBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.dense_blocks = nn.Sequential(\n",
    "            DenseResidualBlock(filters), DenseResidualBlock(filters), DenseResidualBlock(filters)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense_blocks(x).mul(self.res_scale) + x\n",
    "class GeneratorRRDB(nn.Module):\n",
    "    def __init__(self, channels, filters=64, num_res_blocks=16, num_upsample=2):\n",
    "        super(GeneratorRRDB, self).__init__()\n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Conv2d(channels, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        # Second conv layer post residual blocks\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1)\n",
    "        # Upsampling layers\n",
    "        upsample_layers = []\n",
    "        for _ in range(num_upsample):\n",
    "            upsample_layers += [\n",
    "                nn.Conv2d(filters, filters * 4, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsample_layers)\n",
    "        # Final output block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filters, channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = GeneratorRRDB(1, filters=64, num_res_blocks=1, num_upsample=0)\n",
    "\n",
    "summary(generator, input_size=(1, 64, 64), batch_size=32, device='cpu')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}